---
title: "Analyse des données de consommations d'énergie en Inde"
output: html_notebook
---

# Environnement de travail

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(readxl)
library(tidyr)
library(fda)
```

# Notre base de données

Notre étude porte sur l'analyse de la consommation d'énergie dans les 33 Etats d'Inde. Il est à noter que l’Inde est le troisième producteur et le troisième consommateur d’électricité au monde.


## Importation des données

Dans un premier temps, nous allons importer les données.

```{r}
data <- read.csv("long_data_2.csv", stringsAsFactors = T,sep = ";")

colnames(data) <- c("Etat", "Regions", "latitude", "longitude", "Date", "Consommation")
data <- data[,-c(3,4)]
summary(data)
# View(data)
```

Grâce à ce résumé statistique, nous pouvons voir que les valeurs de nos données de consommation d'énergie sont assez étendues : elles sont comprises entre 0.3 et 522.1 Méga Units.\

```{r}
data$Etat[which.max(data$Consommation)]
data$Etat[which.min(data$Consommation)]
```

En effet, certaines valeurs journalières sont très faibles (inférieures à 1) alors que d'autres sont 500 fois plus élevées. Par exemple, le Maharashtra qui présente certaines valeurs très importantes en opposition avec le Sikkim. 

Concernant notre base de données, elle décrit la consommation d'énergie dans **33 Etats** d'Inde entre 2019 et 2020. \
Nous avons 16 434 lignes, soit **498 points de mesure** par pays (498*33). Les données sont journalières, exprimées en Mega Units.

```{r}
dim(data)
```


## Choix de la période étudiée

Nous allons transformer notre variable Date au format date pour poursuivre l'étude correctement.

```{r}
data$Date <- as.Date(data$Date, format = "%d/%m/%Y %H:%M")
str(data) # Vérification
```

Pour simplifier notre analyse, nous allons nous concentrer seulement sur l'année 2019 : 

```{r}
data <- data |> 
  filter(Date <= as.Date("2020-01-02"))
```

On vérifie à présent que les données que l'on va analyser correspondent bien à la période choisie. 

```{r}
min(data$Date)
max(data$Date)
```

## Normalisation des données 

Au départ, nous avons voulu normaliser les données par le nombre d'habitants de chaque Etat pour que les consommations aient le même impact dans notre étude. Cependant, cette méthode s'est révélée problématique car nous avons obtenu des valeurs très proches de zéro, ce qui aurait compliqué les calculs.

Nous avons donc choisi de réduire les données de consommation, en soustrayant la moyenne, pour continuer notre analyse avec données moins disproportionnées.

```{r, eval=FALSE}
moyenne_par_etat <- tapply(data$Consommation, data$Etat, mean)

normalized_energy <- data
for(i in 1:nrow(normalized_energy)){
  normalized_energy$Consommation[i] <- normalized_energy$Consommation[i] - moyenne_par_etat[normalized_energy$Etat[i]]
}
```


Suite à cette normailisation, nous pouvons observer une diminution importante des valeurs. Mais nous obtenons des valeurs de consommations négatives, ce qui pose problème pour l'interprétation de nos analyses. 
Nous allons donc travailler avec les valeurs initiales. 

## Représentations graphiques 

Nous allons tout d'abord représenter simplement nos données pour pouvoir faire ressortir les informations importantes. 

```{r}
ggplot(data, aes(x = Date, y = Consommation, color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie par Etat") +
  theme_minimal()
```
Ce graphique nous montre que nos données sont très irrégulières. \

[Représentation des données en différentes parties].{underline}

Pour que les informations soient plus lisibles, nous avons décidé de séparer en plusieurs parties nos données.
Nous avons fixé des seuils par rapport à la moyenne de consommations des Etats pour réaliser ces graphiques. 

[Calcul de la moyenne par Etat].{underline}

On calcule d'abord la moyenne par Etat et on ajoute cette moyenne a un nouveau dataframe : 

```{r}
moyenne_par_etat <- tapply(data$Consommation, data$Etat, mean)
moyenne_par_etat <- data.frame(Etat = names(moyenne_par_etat), Moyenne = moyenne_par_etat)

data_complete <- merge(data,moyenne_par_etat, by = "Etat") 
head(data_complete)
```


[Séparation de notre jeu de données].{underline}

On sépare les données en 3 catégories : 

```{r}
data_inf <- data_complete |> 
  filter(Moyenne <= 50)
# data_inf

data_moy <- data_complete |> 
  filter(Moyenne > 50 & Moyenne < 200)
# data_moy

data_sup <- data_complete |> 
  filter(Moyenne >= 200)
# data_sup
```

[Représentations graphiques].{underline}

```{r}
ggplot(data_inf, aes(x = Date, y = Consommation, color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie par Etat", subtitle = "Etats consommant moins de 50 Mega Units en moyenne") +
  theme_minimal()

ggplot(data_moy, aes(x = Date, y = Consommation, color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie par Etat", subtitle = "Etats consommant entre 50 et 200 Mega Units en moyenne") +
  theme_minimal()

ggplot(data_sup, aes(x = Date, y = Consommation, color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie par Etat", subtitle = "Etats consommant plus de 200 Mega Units en moyenne") +
  theme_minimal()
```

Grâce à ces représentations, il est plus facile d'observer et d'étudier l'allure de nos données.\

Pour la plupart des Etats, leur consommation varie beaucoup tout au long de l'année et en quelques jours leur consommation peut doubler ou bien diminuer subitement.

Cependant certains Etats comme le Tripura possède une consommation très faible, et peu de variations dans son signal sont observées :

```{r}
data |> 
  filter(Etat=="Tripura") |> 
  ggplot(aes(x = Date, y = Consommation)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie du Tripura") +
  theme_minimal()
```

Sa consommation varie entre 2.4 et 6.6 mega Units.

```{r}
min(data$Consommation[data$Etat=="Tripura"])
max(data$Consommation[data$Etat=="Tripura"])
```

A l'opposition du Punjab qui lui possède une très grande variation dans sa consommation :

```{r}
min(data$Consommation[data$Etat=="Punjab"])
max(data$Consommation[data$Etat=="Punjab"])
```

[Tableau des moyennes de consommation par Etat]{.underline}

# A METTRE EN JOLIE

```{r}
tapply(data$Consommation, data$Etat, mean)
```



[Représentation selon la région]{.underline}

L'Inde est divisée en 5 regions : le Nord (NR), Nord-Est (NER), le Sud (SR), l'Est (ER) et l'Ouest (WR)
Nous allons tracer les consommations en fonction des régions (une couleur par région)./
De la même manière que les représentations précédentes, nous ne pouvons représenter les régions sur le même graphique. Sans diviser la représentation, il est difficile de bien observer les différences entre les régions.

Nous décidons donc de représenter une région par graphique :

```{r}
data |> 
  filter(Regions=="ER") |> 
  ggplot(aes(x = Date, y = Consommation,color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie pour les Etats de l'Est de l'Inde") +
  theme_minimal()

data |> 
  filter(Regions=="NER") |> 
  ggplot(aes(x = Date, y = Consommation,color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie pour les Etats du Nord Est de l'Inde") +
  theme_minimal()

data |> 
  filter(Regions=="NR") |> 
  ggplot(aes(x = Date, y = Consommation,color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie pour les Etats du Nord de l'Inde") +
  theme_minimal()

data |> 
  filter(Regions=="SR") |> 
  ggplot(aes(x = Date, y = Consommation,color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie pour les Etats du Sud de l'Inde") +
  theme_minimal()

data |> 
  filter(Regions=="WR") |> 
  ggplot(aes(x = Date, y = Consommation,color = Etat)) +
  geom_line() +
  labs(x = "Date", y = "Consommation d'énergie", title = "Consommation d'énergie pour les Etats de l'Ouest de l'Inde") +
  theme_minimal()

```

Au sein de chaque région de l'Inde, nous observons de forts contrastes de consommation d'énergie. Nous pouvons noter une différence d'échelle entre les graphiques. Par exemple, dans le Sud de l'Inde, Pondy a une faible consommation d'énergie (entre 4 et 10 mega Units) à l'opposé de Tamil Nadu où sa consommation varie entre 200 et 370 mega Units.

Il serait intéressant de consulter l'avis d'un économiste ou politicien pour analyser et comprendre ces grandes disparités au sein des régions de l'Inde.


Nous construisons le tableau des moyennes de consommation par région :

# A METTRE EN JOLIE

```{r}
tapply(data$Consommation, data$Regions, mean)
```

Nous observons une hétérogénéité en termes de consommation entre les régions de l'Inde. En effet, le Nord-Est a une consommation très faible par rapport à l'Ouest.


# Ondelettes


Puisque nos signaux sont irréguliers, notre choix de lissage s'est tourné vers les ondelettes car elles ont des bonnes propriétés de compressions et sont adaptées à ce type de données. 

Pour pouvoir poursuivre cette étude, nous avons du transformer notre dataframe de départ pour avoir chaque Etat en colonne avec la valeur de consommation en ligne pour chaque point de mesure. 

```{r, message=FALSE, warning=FALSE}
data_long <- data.frame("Etat" = data$Etat,"Date"= data$Date,"Consommation" = data$Consommation)

data_long <- data_long |> 
  pivot_wider(names_from = "Etat", values_from = "Consommation")

data_long <- as.data.frame(data_long)
head(data_long)
```

Le problème ici est que la longueur des courbes de consommation n'est pas de la forme $2^J$. Ces courbes sont de longueur 356, on symétrise le signal à la fin pour atteindre une longueur de 512. 
On se ramènera à la fin au signal de départ de taille 356.

Nous représentons le signal pour un Etat (ici le Punjab) :

```{r}
i = 2
y <-  data_long[,i]
# y

plot(1:356,y,type="l",main="Signal de départ", ylab = "Consommation", xlab="Jour")

# Créer un signal symétrisé
ysym = c(y, rev(tail(y, n= 512-length(y)))) # on choisit 512 pour avoir une puissance de 2

# Tracer le signal symétrisé
plot(ysym, type = "l", main = "Signal symétrisé", ylab = "Consommation", xlab = "Jour")

# Ajouter une ligne verticale à la position
# axe de symétrie : 361 jours
abline(v = 356, lty = 2)
```

# CONTINUER A COMMENTER PLUS TARD



# Lissage par moindres carrés pénalisés

# JUSTIFIER POURQUOI CE LISSAGE

## Lissage d'une trajectoire

### Pour un Etat

```{r}
i = 2
y <- data_long[, 2] 
tps <- 1:356
plot(tps,y,type="l", main = "Consommation d'énergie du Punjab")
```

```{r}
i = 10
y <- data_long[, i] # courbe du dixième Etat : Chhattisgarh
tps <- 1:356
plot(tps,y,type="l", main = "Consommation d'énergie du Chhattisgarh")
```

#### Lissage par moindres carrés pénalisés sur la première courbe


```{r,message=FALSE,warning=FALSE}
splbasis = create.bspline.basis(rangeval = c(min(data$Consommation),max(data$Consommation)),
                                norder=6, 
                                breaks=seq(min(data$Consommation),
                                           max(data$Consommation),length=35))
# définition une base de B-spline entre 1 et 356 (les dates) 
# ordre 4 (classique) 
# breaks : coupure


plot(splbasis)
```

```{r}
summary(splbasis)
```
# a commenter

```{r}
i = 2
y = data_long[,i]
gcv = 1:30 # grille de lambda
for (i in 1:30){
  lambda = exp(i-10) 
  fdpar= fdPar(splbasis,Lfdobj =4,lambda=lambda)
  smoothdata = smooth.basis(tps,y,fdParobj = fdpar) 
  gcv[i] = smoothdata$gcv 
}
plot(gcv)
which.min(gcv)
```

# A COMMENTER

```{r}
lambda = exp(which.min(gcv)-10)
fdparTemp = fdPar(splbasis,Lfdobj = 4,lambda=lambda) 
smoothdata = smooth.basis(tps,y,fdParobj = fdpar)
```

Nous représentons sur un même graphe les observations et la fonction estimée reconstruite ˆf.

```{r,message=FALSE,warning=FALSE}
plotfit.fd(y,# valeur de consommation pour un pays
           tps, # les dates
           smoothdata$fd, # nos données estimées
           # 1 à 356 
           pch=20,
           cex=0.5,
           main="les observations et la fonction estimée reconstruite ˆf",
           ylab = "consommation d'énergie",
           xlab="temps")
```
# PB SIGNAL TROP LONG


Représente les points et l'objet fonctionnel ajusté dessus Objet pas trop oscillante et qui suit les points (peu ne pas suivre exactement si bruit de mesure)

```{r}
fhatprim = eval.fd(tps,smoothdata$fd,Lfdobj=1)
fhatpprim = eval.fd(tps,smoothdata$fd,Lfdobj=2)
matplot(tps,cbind(fhatprim,fhatpprim),type="l")
```


### Pour l'ensemble des Etats

On fait l'ajustement pour différentes valeurs de lambda pour minimiser le critère de pénalité.
On veut la fonction la plus proche des points et la moins oscillante grâce à la pénalité


```{r}
gcv = rep(0,30) # grille de lambda

for (i in 1:30){
  lambda = exp(i-10)
  fdpar = fdPar(splbasis,Lfdobj = 4,lambda=lambda) 
  # calcul de la valeur de pénalité
  # Lfdoj = 4 : ordre de la dérivée dans la pénalité (dérivée seconde)
  
  smoothdata = smooth.basis(tps,as.matrix(data_long[,c(-1)]), fdParobj = fdpar)   # ajustement de l'objet fonctionnel
  # donne la valeur du critère VC de Moindres Carrés Généralisé
  
  gcv[i] = mean(smoothdata$gcv) # gcv : general cross validation
}
plot(gcv)
which.min(gcv)
```

Nous avons observé que la valeur optimale de lambda est la 16ème valeur, correspondant au minimum. Cette valeur nous permettra d'être proche des données observées. \
Nous avons choisi de paramétrer le nombre de coupures à 35 car les signaux sont très irréguliers et nous souhaitons être  proche, raisonnablement, du signal d'origine. Ce choix est arbitraire car il peut engendrer du sur-apprentissage si le nombre de coupures est trop élevée par rapport au signal de départ.


Nous allons recalculer la pénalité et refaire le lissage avec la valeur de lambda minimale : 

```{r}
lambda = exp(which.min(gcv)-10)
fdpar = fdPar(splbasis,Lfdobj = 4,lambda=lambda) # calcul pénalité
smoothdata = smooth.basis(tps,as.matrix(data_long[,c(-1)]),fdParobj = fdpar) # lissage
```


On a représenté les points et l'objet fonctionnel. 

```{r}
fhatsmooth <- eval.fd(tps, smoothdata$fd)
```


#### Représentation pour l'ensemble des Etats

Nous représentons les observations et la fonction estimée reconstruite ˆf.

```{r}
matplot(tps,data_long[,c(-1)],type="l",lty=1,ylab="",main="donnees brutes")
matplot(tps,fhatsmooth,type="l",lty=1,ylab="",main="donnees lissees")
```



# IDEE :
la prof a dit que ça dépendait de nos objectifs. Comme on a pas une base d'ondelettes, est-ce qu'on va réellement pouvoir reproduire le signal ?
Donc notre objectif ça pourrait être d'avoir un signal "+ lisse" ?
à voir

```{r}
fhatprim = eval.fd(tps,smoothdata$fd,Lfdobj=1) # dérivé première
# eval.fd : évalue sur les dates
fhatpprim = eval.fd(tps,smoothdata$fd,Lfdobj=2) # dérivé seconde
matplot(tps,cbind(fhatprim,fhatpprim),type="l")
```



# Statistiques exploratoire

## Moyenne fonctionnelle

Nous calculons la moyenne de notre objet fonctionnel :

```{r}
mean_smooth_data = mean.fd(smoothdata$fd)
# mean_smooth_data
```

```{r}
matplot(fhatsmooth,col="gray",type="l",
        xlab="jours",
        ylab="Consommation d'énergie")
lines(mean_smooth_data,lwd=2) # moyenne
```

## Ecart-type fonctionnel

```{r}
sd_smooth_data= sd.fd(smoothdata$fd)
```

```{r}
matplot(fhatsmooth,
        col="gray",type="l",
        xlab="jours",
        ylab="Consommation d'énergie",
        ylim = c(-200,500))
fnmoy = eval.fd(y,mean_smooth_data)
fnsd  = eval.fd(y,sd_smooth_data)
lines(fnmoy,lwd=2)
lines(fnmoy+2*fnsd,lwd=2,col=4,lty=2)
lines(fnmoy-2*fnsd,lwd=2,col=4,lty=2)
```

## Surface de covariance et corrélation

### Covariance

```{r}
cov = var.fd(smoothdata$fd)
surfcov = eval.bifd(seq(1,356,length=35),seq(1,356,length=35),cov)
```

Pour le tracé d'une surface, il est préférable de choisir un nombre modéré de points dans la grille d'évaluation (la représentation est rapidement illisible dans le cas contraire). Ici, nous choisissons arbitrairement 30 points répartis entre 1 et 365.

```{r}
persp(surfcov,col="gray",theta=30,xlab="jours",ylab="jours",zlab="covariance")
```
# A COMMENTER

```{r}
contour(surfcov)
```

Ligne de niveau
# A COMMENTER

### Représentation graphique en couleur

```{r}
filled.contour(surfcov)
```

### Corrélation

De même pour la corrélation

```{r}
cor = cor.fd(seq(1,356,length=35),smoothdata$fd)
```

Elle renvoie directement la matrice de corrélation empirique évaluée en les points demandés

```{r}
persp(cor,col="gray",theta=90,
      phi=40,xlab="jours",
      ylab="jours",zlab="corrélation")
```

### Représentation graphique en couleur

```{r}
filled.contour(cor)
```


### ACP fonctionnelle

```{r}
ACPF = pca.fd(smoothdata$fd,nharm=4,centerfns = TRUE)
ACPF$varprop
cumsum(ACPF$varprop)
```

La première composante explique 99% de la variabilité. 


### Représentations des composantes principales

Nous représentons en premier lieu les composantes principales obtenues

```{r}
plot(ACPF$harmonics)
```

La première est en noir est tout le temps positive.


Donc plus de poids dans les mois d'hiver et moins de poids dans les mois d'été

Ou, pour une interprétation plus aisée, la moyenne augmentée ou diminuée des premières fonctions propres.

On peut utilisée la fonction `plot.pca.fd` pour cette représentation.

```{r}
plot.pca.fd(ACPF)
```
Il est logique de retrouver des graphiques avec des courbes quasiments égales à 0 car la première composante explique quasiment 100% de la variabilité.


### Représentation des individus

[Représentation des individus dans le premier plan factoriel]{.underline}

Les scores des individus sont stockés dans la matrice `scores` de `ACPF`

```{r}
head(ACPF$scores)
plot(ACPF$scores[,1],
     ACPF$scores[,2],
     pch=20,
     xlab="FPC 1",
     ylab="FPC 2",
     type="n")
nomsvilles = colnames(data_long[,c(-1)])
r = as.factor(data$Regions)
text(ACPF$scores[,1],
     ACPF$scores[,2],
     labels=nomsvilles,cex=0.7,col=as.numeric(r))
legend("topleft",legend = levels(climat),col=1:4,lty=1)
```

Nous arrivons à distinguer les consommations d'énergie selon la région. Cependant, nous observons quelques exceptions.

Pour la première compostante principale (abscisse), les Etats concentrés à droite du graphique présentent des valeurs de consommations d'énergie élevées. Par exemple, Telangana et l'Etat du Madhya Pradesh (MP) et Gujarat sont des grands consommateurs d'énergies.

Pour la deuxième composante principale (ordonnée), pour les Etats situés en haut du graphique, cela indique que leur consommation d'énergie est très variable selon les périodes de l'année. L'Etat du Punjab et Haryana présentent beaucoup d'écarts de valeurs. \ 
Pour les petites valeurs, les Etats présentent des consommations plus stables. Cette observation est en adéquation avec les premières représentations graphiques que nous avons réalisées au début de ce rapport.



# Sources 

- base de données : https://www.kaggle.com/datasets/twinkle0705/state-wise-power-consumption-in-india?fbclid=IwAR3tNVrXpTrRlO_HVOoa53bcaTR8aR7QU_Nlbe4AhhmfzdK9ERa5Xxid1yk
- nombre d'habitants par pays : https://fr.zhujiworld.com/in/673630-tripura/?fbclid=IwAR2Ua_lx2k7u-Nil065Pw0S0mK682X7e8AuvR5CS7lfpsbUBPIlEzNiwE2Q